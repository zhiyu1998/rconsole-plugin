import{_ as e,c as o,o as i,ab as t}from"./chunks/framework.BA8ZoOPC.js";const m=JSON.parse('{"title":"CLAUDE.md","description":"","frontmatter":{},"headers":[],"relativePath":"CLAUDE.md","filePath":"CLAUDE.md"}'),a={name:"CLAUDE.md"},s=t('<h1 id="claude-md" tabindex="-1">CLAUDE.md <a class="header-anchor" href="#claude-md" aria-label="Permalink to &quot;CLAUDE.md&quot;">​</a></h1><p>This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.</p><h2 id="architecture" tabindex="-1">Architecture <a class="header-anchor" href="#architecture" aria-label="Permalink to &quot;Architecture&quot;">​</a></h2><p>This project is a plugin for the Yunzai-Bot. It provides various features, including video and link parsing from different social media platforms, music features, and other tools.</p><p>The main components are:</p><ul><li><code>index.js</code>: The plugin entry point.</li><li><code>apps/</code>: Contains the main logic for different commands and features offered by the plugin.</li><li><code>model/</code>: Contains business logic and data handling for different features.</li><li><code>utils/</code>: Contains utility functions for interacting with external services like Bilibili, YouTube, TikTok, etc.</li><li><code>config/</code>: YAML configuration files for the plugin.</li><li><code>resources/</code>: Contains templates (HTML, CSS) and images for generating rich responses.</li></ul><h2 id="common-development-tasks" tabindex="-1">Common Development Tasks <a class="header-anchor" href="#common-development-tasks" aria-label="Permalink to &quot;Common Development Tasks&quot;">​</a></h2><h3 id="installing-dependencies" tabindex="-1">Installing Dependencies <a class="header-anchor" href="#installing-dependencies" aria-label="Permalink to &quot;Installing Dependencies&quot;">​</a></h3><p>To install the required dependencies, run the following command in the root directory of the Yunzai-Bot:</p><div class="language-bash vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;" tabindex="0"><code><span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">pnpm</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> i</span><span style="--shiki-light:#A65E2B;--shiki-dark:#C99076;"> --filter=rconsole-plugin</span></span></code></pre></div><h3 id="video-parsing" tabindex="-1">Video Parsing <a class="header-anchor" href="#video-parsing" aria-label="Permalink to &quot;Video Parsing&quot;">​</a></h3><p>The video parsing feature requires <code>ffmpeg</code> to be installed on the system.</p><p>For Ubuntu:</p><div class="language-bash vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;" tabindex="0"><code><span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">sudo</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> apt-get</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> install</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> ffmpeg</span></span></code></pre></div><p>Refer to the <code>README.md</code> for installation on other systems.</p><p>There are no specific build, linting, or testing commands mentioned in the repository. Development seems to follow the standards of the Yunzai-Bot ecosystem.</p><h2 id="coding-conventions" tabindex="-1">Coding Conventions <a class="header-anchor" href="#coding-conventions" aria-label="Permalink to &quot;Coding Conventions&quot;">​</a></h2><p>When making changes to this codebase, please adhere to the following principles:</p><ul><li><strong>Keep It Simple, Stupid (KISS):</strong> Write code that is simple, straightforward, and easy to understand. Avoid introducing unnecessary complexity.</li><li><strong>Don&#39;t Repeat Yourself (DRY):</strong> Instead of duplicating code for similar functionalities, create generic, reusable functions. A good example is the <code>initProviderFilter</code> function in <code>scripts/settings.js</code>, which handles filtering logic for multiple providers in a unified way.</li><li><strong>Use Precise Regular Expressions:</strong> As seen in issue #77, overly broad regular expressions (e.g., <code>mp.weixin</code>) can lead to incorrect message handling. Regular expressions in the <code>rule</code> definitions should be as specific as possible (e.g., <code>mp.weixin.qq.com</code>) to avoid false positives.</li><li><strong>Use Message Recall Judiciously:</strong> The <code>e.reply</code> function supports an optional parameter to recall (delete) the original message. This should be used with caution. Automatically deleting a user&#39;s message can be a negative experience, especially for administrators. In issue #77, this was disabled for link summaries to prevent the original shared link from being deleted.</li><li><strong>Logging Conventions:</strong> The project uses a global <code>logger</code> object for logging. When adding logs, please follow these conventions: <ul><li>Log messages should be prefixed with <code>[R插件][模块名称]</code> (e.g., <code>[R插件][BILI下载]</code>) to provide clear context.</li><li>Use the appropriate log level: <ul><li><code>logger.info</code>: For general informational messages about the execution flow.</li><li><code>logger.error</code>: For critical errors, exceptions, and failures. Always include the error object if available.</li><li><code>logger.warn</code>: For non-critical issues or potential problems that do not prevent the current operation from completing.</li><li><code>logger.debug</code>: For detailed, verbose information that is useful for debugging but not needed for normal operation.</li><li><code>logger.mark</code>: For highlighting important events or milestones in the code.</li></ul></li></ul></li><li><strong>Enhance Network Request Robustness:</strong> When interacting with external services, network requests may occasionally fail due to transient issues (e.g., <code>Client network socket disconnected</code>). To mitigate this, implement a retry mechanism for network requests. The project provides <code>retryAxiosReq</code> for <code>axios</code> and <code>retryFetch</code> for <code>fetch</code> in <code>utils/common.js</code>. Use these utility functions to wrap network calls and improve the reliability of features that depend on external APIs.</li></ul><h2 id="ai-integration-patterns" tabindex="-1">AI Integration Patterns <a class="header-anchor" href="#ai-integration-patterns" aria-label="Permalink to &quot;AI Integration Patterns&quot;">​</a></h2><p>The plugin integrates with various AI models for features like link summarization. The following patterns are used to ensure flexibility and extensibility.</p><h3 id="provider-abstraction-utils-openai-builder-js" tabindex="-1">Provider Abstraction (<code>utils/openai-builder.js</code>) <a class="header-anchor" href="#provider-abstraction-utils-openai-builder-js" aria-label="Permalink to &quot;Provider Abstraction (`utils/openai-builder.js`)&quot;">​</a></h3><p>The <code>OpenaiBuilder</code> class acts as a factory and client for interacting with different AI providers. It is designed to be extensible.</p><ul><li><strong><code>provider</code> property</strong>: A <code>provider</code> string (&#39;kimi&#39;, &#39;deepseek&#39;, etc.) is set on the builder instance to control which logic to use.</li><li><strong><code>chat()</code> method</strong>: This central method contains a conditional block (e.g., <code>if (this.provider === &#39;deepseek&#39;)</code>) to call the appropriate function for the selected provider. For OpenAI-compatible APIs, it constructs and sends a standard request. For others, it can delegate to custom functions (like <code>deepSeekChat</code> from <code>utils/llm-util.js</code>).</li><li><strong>Adding New Providers</strong>: To add a new AI provider, you should: <ol><li>Add a new condition in the <code>chat</code> method within <code>OpenaiBuilder</code>.</li><li>Implement the provider-specific logic, either directly or in a separate utility function.</li><li>Update the calling code (e.g., in <code>apps/tools.js</code>) to set the new provider on the builder based on configuration (<code>this.aiModel</code>).</li></ol></li></ul><h3 id="tool-calling-for-ai-models" tabindex="-1">Tool-Calling for AI Models <a class="header-anchor" href="#tool-calling-for-ai-models" aria-label="Permalink to &quot;Tool-Calling for AI Models&quot;">​</a></h3><p>For AI models that support it (like Kimi/Moonshot), the application uses a tool-calling mechanism to allow the AI to fetch information on its own.</p><ul><li><strong>Tool Definition (<code>constants/tools.js</code>)</strong>: Tools like <code>CRAWL_TOOL</code> are defined with a JSON schema that the AI model can understand.</li><li><strong>Orchestration (<code>apps/tools.js</code>)</strong>: The <code>linkShareSummary</code> function manages the conversation flow. It sends the initial user request along with the available tools. If the model responds with a <code>tool_calls</code> request, the application executes the requested function (e.g., <code>llmRead</code> for the <code>crawl</code> tool), and sends the results back to the model in a new message with <code>role: &#39;tool&#39;</code>. This loop continues until the model returns a final text-based answer.</li></ul><h3 id="fallback-for-non-tool-calling-models" tabindex="-1">Fallback for Non-Tool-Calling Models <a class="header-anchor" href="#fallback-for-non-tool-calling-models" aria-label="Permalink to &quot;Fallback for Non-Tool-Calling Models&quot;">​</a></h3><p>A fallback mechanism is in place for models that do not support tool-calling.</p><ul><li>In <code>linkShareSummary</code>, there&#39;s a check on the model name (<code>!this.aiModel.includes(&quot;kimi&quot;) &amp;&amp; !this.aiModel.includes(&quot;moonshot&quot;)</code>).</li><li>If the model is not expected to support tools, the application proactively fetches the content of the URL using <code>llmRead</code> first.</li><li>It then sends the fetched content directly to the AI model for summarization, without offering any tools. This ensures that the summarization feature works across a wider range of AI models.</li></ul>',30),n=[s];function l(r,d,c,h,p,u){return i(),o("div",null,n)}const f=e(a,[["render",l]]);export{m as __pageData,f as default};
